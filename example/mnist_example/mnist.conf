
#STEPS: "encode,train",
#STEPS: "encode,predict"
STEPS: "encode,evaluate",

HDFS_WORKSPACE : "dlflow outputs files will be put here",
LOCAL_WORKSPACE : "./mnist"


HDFS_ENCODE_DIR : "$HDFS_WORKSPACE/encode/TAG=$FEATURE_TAG/<dt=$FEATURE_DATE:yyyy/mm/dd>",
HDFS_TFRECORD_DIR : "$HDFS_WORKSPACE/tfrecord/TAG=$FEATURE_TAG/<dt=$FEATURE_DATE:yyyy/mm/dd>",
HDFS_PREDICT_DIR:"$HDFS_WORKSPACE/predict/TAG=$FEATURE_TAG/<dt=$FEATURE_DATE:yyyy/mm/dd>",
HDFS_FEATURE_DIR:"Put the path of the feature file here. 
                  At the same time, the feature needs to include the label and the primary key. 
                  When you are doing testing or predicting step, 
                  the label can be specified as any value, it is just a placeholder",


MODEL_TAG : "cnn",
FEATURE_TAG : "mnist",
MODEL_DATE : "20200710",
FEATURE_DATE : "20200711",
PRIMARY_KEYS : "index",
LABELS : "label",
DROP_COLUMNS: ""#columns that you dont need them partipate in training

MODELS_DIR : "your project path/dlflow/example/mnist_example/model/"#path can be revised as long as the model folder can be founed


MODEL: {
    model_name: "mnist_cnn",#this model name as same as your model name registed in your scripts,see mnist_classifier.py
    input_name: "NNDenseInput",
    classes: 1,
    learning_rate: 0.001,
    batch_size: 64,
    epochs: 10
},



SPARK: {
    master: "",
    driver-memory: "4g",
    spark.submit.deployMode: "",
    spark.yarn.queue: "",
    spark.dynamicAllocation.enabled: "true",
    spark.dynamicAllocation.minExecutors: "300",
    spark.dynamicAllocation.maxExecutors: "600",
    spark.executor.cores: "4",
    spark.executor.memory: "10g",
    spark.executor.memoryOverhead: "5g",
    spark.default.parallelism: "2000",
    spark.sql.shuffle.partitions: "2000",
    spark.yarn.dist.archives:"",
    spark.jars:"some path/tensorflow-hadoop-1.12.0.jar,some path/spark-tensorflow-connector_2.11-1.12.0.jar",
    spark.executorEnv.PYSPARK_PYTHON:"spark excute python enviroment on each nodes"
    
},
