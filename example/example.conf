
IRIS_DATASET_FOR: "train",

STEPS: "data_prepare, encode, train, evaluate, predict",

LOCAL_WORKSPACE : "./my_workspace"
HDFS_WORKSPACE : "<SET_YOUR_HDFS_WORKSPACE_HERE>",

MODEL_TAG : "iris_model_v0",
FEATURE_TAG : "iris_feature_v0",
MODEL_DATE : "20200229",
FEATURE_DATE : "20200229",
PRIMARY_KEYS : "idx",
LABELS : "species",

MODELS_DIR : "./my_model"
TASKS_DIR: "./my_tasks"

SPARK: {
    master: "yarn",
    driver-memory: "4g",
    spark.submit.deployMode: "client",
    spark.yarn.queue: "<SET_YOUR_YARN_QUEUE_HERE>",
    spark.dynamicAllocation.enabled: "true",
    spark.dynamicAllocation.minExecutors: "2",
    spark.dynamicAllocation.maxExecutors: "8",
    spark.executor.cores: "1",
    spark.executor.memory: "3g",
    spark.executor.memoryOverhead: "1g",
    spark.default.parallelism: "10",
    spark.sql.shuffle.partitions: "10",
    <MAY_SET_OTHER_SPARK_CONFIG>: <MAY_SET_OTHER_SPARK_CONFIG>
},

MODEL: {
    model_name: "my_model",
    input_name: "NNDenseInput",
    layers: [16, 8],
    classes: 3,

    learning_rate: 0.1,
    batch_size: 4,
    epochs: 3
},

BUCKET: {
    "sepal" : {
        features: [
            "sepal_length",
            "sepal_width"
        ],
        is_encode: true,
        method: "pnorm",
        param: {"p": 1.0}
    },

    "petal" : {
        features: [
            "petal_length",
            "petal_width"
        ],
        is_encode: true,
        method: "zscore"
    }
}
